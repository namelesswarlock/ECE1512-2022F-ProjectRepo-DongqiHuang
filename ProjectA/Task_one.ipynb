{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WYMfvCNPwpm"
      },
      "source": [
        "# Project A: Knowledge Distillation for Building Lightweight Deep Learning Models in Visual Classification Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA8ppgB2P0aJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install keras-flops\n",
        "from keras_flops import get_flops\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from typing import Union\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "builder = tfds.builder('mnist')\n",
        "BATCH_SIZE = 256\n",
        "NUM_EPOCHS = 12\n",
        "NUM_CLASSES = 10  # 10 total classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2EFLQROP2R7"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "8243bedb0c904be0b0fe0dc96604e0a9",
            "45c7cc4619bf47abb1cd976141d091bc",
            "e62dc2c9605a42988b2e47b0e35b2f30",
            "e0f1d2dd3cf646899ff82ff53b58ebf1",
            "dd9d6bba363d4fe590d7237576f70ea9",
            "18fd9d363c81431daaa918f9963f80f6",
            "957c4be3e82a4fcabcab21abe0c9d780",
            "35e6aaa9cf1246488a43dfb216d2ef90",
            "a9ea82867511487b8e494927542ec44b",
            "a1902bcc505849918ca9dce2af531d3b",
            "87e41978fe394e3f839dda884a66301b"
          ]
        },
        "id": "ynByMG_UP4A4",
        "outputId": "6d1ea586-c776-441b-b6a4-c23093453f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to ~/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8243bedb0c904be0b0fe0dc96604e0a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDataset mnist downloaded and prepared to ~/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
            "mnist_train shape: <BatchDataset element_spec=(TensorSpec(shape=(256, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(256, 10), dtype=tf.float32, name=None))>\n",
            "mnist_test shape: <BatchDataset element_spec=(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "# Load train and test splits.\n",
        "def preprocess(x):\n",
        "  image = tf.image.convert_image_dtype(x['image'], tf.float32)\n",
        "  subclass_labels = tf.one_hot(x['label'], builder.info.features['label'].num_classes)\n",
        "  return image, subclass_labels\n",
        "\n",
        "\n",
        "mnist_train = tfds.load('mnist', split='train', shuffle_files=False).cache()\n",
        "mnist_train = mnist_train.map(preprocess)\n",
        "mnist_train = mnist_train.shuffle(builder.info.splits['train'].num_examples)\n",
        "mnist_train = mnist_train.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "mnist_test = tfds.load('mnist', split='test').cache()\n",
        "mnist_test = mnist_test.map(preprocess).batch(BATCH_SIZE)\n",
        "print('mnist_train shape:', mnist_train)\n",
        "print('mnist_test shape:', mnist_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAZwfvW5P63q"
      },
      "source": [
        "# Model creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zINgDkA7P7BP",
        "outputId": "7fed3f2b-7b38-4475-88af-bd776a73b081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 25, 25, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 20000)             0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 20000)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 256)               5120256   \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,123,146\n",
            "Trainable params: 5,123,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 25, 25, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 23, 23, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 11, 11, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 7744)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 7744)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               991360    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,011,466\n",
            "Trainable params: 1,011,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 748)               587180    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 748)               560252    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                7490      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,154,922\n",
            "Trainable params: 1,154,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "##@ test {\"output\": \"ignore\"}\n",
        "\n",
        "# Teacher.\n",
        "mod1 = tf.keras.Sequential()\n",
        "\n",
        "# your code start from here for step 2\n",
        "mod1.add(tf.keras.layers.Conv2D(32, (3,3), strides=1, activation=\"relu\",input_shape=(28, 28,1)))\n",
        "mod1.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=1))\n",
        "mod1.add(tf.keras.layers.Conv2D(64, (3,3), strides=1, activation=\"relu\"))\n",
        "mod1.add(tf.keras.layers.MaxPooling2D((2, 2), strides=2))\n",
        "mod1.add(tf.keras.layers.Flatten())\n",
        "mod1.add(tf.keras.layers.Dropout(0.5))\n",
        "mod1.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
        "mod1.add(tf.keras.layers.Dropout(0.5))\n",
        "mod1.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
        "\n",
        "\n",
        "# Dnn student\n",
        "\n",
        "# your code start from here for step 2\n",
        "stu_mod = tf.keras.Sequential()\n",
        "stu_mod.add(tf.keras.layers.Flatten(input_shape=( 28, 28,1)))\n",
        "stu_mod.add(tf.keras.layers.Dense(748, activation=\"relu\"))\n",
        "stu_mod.add(tf.keras.layers.Dense(748, activation=\"relu\"))\n",
        "stu_mod.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
        "\n",
        "# teacher 2.\n",
        "model_t = tf.keras.Sequential()\n",
        "\n",
        "model_t.add(tf.keras.layers.Conv2D(32, (3,3), strides=1, activation=\"relu\",input_shape=(28, 28,1)))\n",
        "model_t.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=1))\n",
        "model_t.add(tf.keras.layers.Flatten())\n",
        "model_t.add(tf.keras.layers.Dropout(0.5))\n",
        "model_t.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
        "model_t.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
        "\n",
        "\n",
        "model_t.summary()\n",
        "\n",
        "mod1.summary()\n",
        "stu_mod.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JWGucyrQGav"
      },
      "source": [
        "# Teacher loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In0079-f2NvP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhzBP6ZLQJ57"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def compute_teacher_loss(images, labels):\n",
        "  \"\"\"Compute subclass knowledge distillation teacher loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  subclass_logits = cnn_model(images, training=True)\n",
        "\n",
        " \n",
        "  cross_entropy_loss_value=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=subclass_logits))\n",
        "  \n",
        "\n",
        "\n",
        "  return cross_entropy_loss_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS8xkuH0QbOS"
      },
      "source": [
        "# Student loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDKia4gPQMIr"
      },
      "outputs": [],
      "source": [
        "#@ test {\"output\": \"ignore\"}\n",
        "\n",
        "# Hyperparameters for distillation (need to be tuned).\n",
        "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 4. #temperature hyperparameter\n",
        "\n",
        "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
        "                      temperature: Union[float, tf.Tensor]):\n",
        "  \"\"\"Compute distillation loss.\n",
        "\n",
        "  This function computes cross entropy between softened logits and softened\n",
        "  targets. The resulting loss is scaled by the squared temperature so that\n",
        "  the gradient magnitude remains approximately constant as the temperature is\n",
        "  changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
        "  a neural network.\"\n",
        "\n",
        "  Args:\n",
        "    teacher_logits: A Tensor of logits provided by the teacher.\n",
        "    student_logits: A Tensor of logits provided by the student, of the same\n",
        "      shape as `teacher_logits`.\n",
        "    temperature: Temperature to use for distillation.\n",
        "\n",
        "  Returns:\n",
        "    A scalar Tensor containing the distillation loss.\n",
        "  \"\"\"\n",
        " # your code start from here for step 3\n",
        "  soft_targets = tf.exp(teacher_logits/temperature) / tf.reduce_sum(tf.exp(teacher_logits/temperature), -1, keepdims=True)\n",
        "\n",
        "  return tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "\n",
        "def compute_student_loss(images, labels):\n",
        "  \"\"\"Compute subclass knowledge distillation student loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  student_subclass_logits = fc_model(images, training=True)\n",
        "\n",
        "  # Compute subclass distillation loss between student subclass logits and\n",
        "  # softened teacher subclass targets probabilities.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  teacher_subclass_logits = cnn_model(images, training=False)\n",
        "  distillation_loss_value =distillation_loss(teacher_subclass_logits,student_subclass_logits,DISTILLATION_TEMPERATURE)\n",
        "\n",
        "  # Compute cross-entropy loss with hard targets.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  cross_entropy_loss_value = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=student_subclass_logits))\n",
        "\n",
        "  return ALPHA*distillation_loss_value+(1-ALPHA)*cross_entropy_loss_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ1uyvurQ3w4"
      },
      "source": [
        "# Train and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtoLbp8uQ4Vl"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def compute_num_correct(model, images, labels):\n",
        "  \"\"\"Compute number of correctly classified images in a batch.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Number of correctly classified images.\n",
        "  \"\"\"\n",
        "  class_logits = model(images, training=False)\n",
        "  return tf.reduce_sum(\n",
        "      tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
        "              tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)\n",
        "\n",
        "\n",
        "def train_and_evaluate(model, compute_loss_fn):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001)\n",
        "  test_acc = []\n",
        "  for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    for images, labels in mnist_train:\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4 \n",
        "        \n",
        "        loss_value = compute_loss_fn(images, labels)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "\n",
        "    num_total = builder.info.splits['test'].num_examples\n",
        "    for images, labels in mnist_test:\n",
        "      # your code start from here for step 4\n",
        "      \n",
        "      num_correct += compute_num_correct(model, images, labels)[0]\n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "    test_acc.append(num_correct / num_total * 100)\n",
        "    \n",
        "  return max(test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQL1lJdaRPT1"
      },
      "source": [
        "# Training models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AGHbyABRPz3",
        "outputId": "58155470-4cb2-4c36-f47f-9a0b35eed0fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Class_accuracy: 98.02%\n",
            "Epoch 2: Class_accuracy: 98.42%\n",
            "Epoch 3: Class_accuracy: 98.97%\n",
            "Epoch 4: Class_accuracy: 98.77%\n",
            "Epoch 5: Class_accuracy: 98.97%\n",
            "Epoch 6: Class_accuracy: 99.03%\n",
            "Epoch 7: Class_accuracy: 99.05%\n",
            "Epoch 8: Class_accuracy: 99.27%\n",
            "Epoch 9: Class_accuracy: 99.06%\n",
            "Epoch 10: Class_accuracy: 99.22%\n",
            "Epoch 11: Class_accuracy: 99.24%\n",
            "Epoch 12: Class_accuracy: 99.14%\n",
            "alpha: 0.3\n",
            "temperature: 1\n",
            "Epoch 1: Class_accuracy: 96.93%\n",
            "Epoch 2: Class_accuracy: 97.41%\n",
            "Epoch 3: Class_accuracy: 97.87%\n",
            "Epoch 4: Class_accuracy: 97.86%\n",
            "Epoch 5: Class_accuracy: 98.15%\n",
            "Epoch 6: Class_accuracy: 98.09%\n",
            "Epoch 7: Class_accuracy: 98.49%\n",
            "Epoch 8: Class_accuracy: 98.44%\n",
            "Epoch 9: Class_accuracy: 98.26%\n",
            "Epoch 10: Class_accuracy: 98.12%\n",
            "Epoch 11: Class_accuracy: 98.44%\n",
            "Epoch 12: Class_accuracy: 98.38%\n",
            "alpha: 0.3\n",
            "temperature: 2\n",
            "Epoch 1: Class_accuracy: 98.47%\n",
            "Epoch 2: Class_accuracy: 98.47%\n",
            "Epoch 3: Class_accuracy: 98.60%\n",
            "Epoch 4: Class_accuracy: 98.49%\n",
            "Epoch 5: Class_accuracy: 98.55%\n",
            "Epoch 6: Class_accuracy: 98.58%\n",
            "Epoch 7: Class_accuracy: 98.66%\n",
            "Epoch 8: Class_accuracy: 98.75%\n",
            "Epoch 9: Class_accuracy: 98.76%\n",
            "Epoch 10: Class_accuracy: 98.70%\n",
            "Epoch 11: Class_accuracy: 98.74%\n",
            "Epoch 12: Class_accuracy: 98.72%\n",
            "alpha: 0.3\n",
            "temperature: 4\n",
            "Epoch 1: Class_accuracy: 98.79%\n",
            "Epoch 2: Class_accuracy: 98.85%\n",
            "Epoch 3: Class_accuracy: 98.85%\n",
            "Epoch 4: Class_accuracy: 98.84%\n",
            "Epoch 5: Class_accuracy: 98.88%\n",
            "Epoch 6: Class_accuracy: 98.83%\n",
            "Epoch 7: Class_accuracy: 98.86%\n",
            "Epoch 8: Class_accuracy: 98.88%\n",
            "Epoch 9: Class_accuracy: 98.92%\n",
            "Epoch 10: Class_accuracy: 98.92%\n",
            "Epoch 11: Class_accuracy: 98.92%\n",
            "Epoch 12: Class_accuracy: 98.93%\n",
            "alpha: 0.3\n",
            "temperature: 16\n",
            "Epoch 1: Class_accuracy: 98.99%\n",
            "Epoch 2: Class_accuracy: 98.95%\n",
            "Epoch 3: Class_accuracy: 98.96%\n",
            "Epoch 4: Class_accuracy: 98.94%\n",
            "Epoch 5: Class_accuracy: 98.92%\n",
            "Epoch 6: Class_accuracy: 98.91%\n",
            "Epoch 7: Class_accuracy: 98.93%\n",
            "Epoch 8: Class_accuracy: 98.95%\n",
            "Epoch 9: Class_accuracy: 98.96%\n",
            "Epoch 10: Class_accuracy: 98.92%\n",
            "Epoch 11: Class_accuracy: 98.95%\n",
            "Epoch 12: Class_accuracy: 98.97%\n",
            "alpha: 0.3\n",
            "temperature: 32\n",
            "Epoch 1: Class_accuracy: 98.97%\n",
            "Epoch 2: Class_accuracy: 98.95%\n",
            "Epoch 3: Class_accuracy: 98.98%\n",
            "Epoch 4: Class_accuracy: 98.95%\n",
            "Epoch 5: Class_accuracy: 98.88%\n",
            "Epoch 6: Class_accuracy: 98.97%\n",
            "Epoch 7: Class_accuracy: 98.91%\n",
            "Epoch 8: Class_accuracy: 98.92%\n",
            "Epoch 9: Class_accuracy: 98.92%\n",
            "Epoch 10: Class_accuracy: 98.95%\n",
            "Epoch 11: Class_accuracy: 98.95%\n",
            "Epoch 12: Class_accuracy: 98.96%\n",
            "alpha: 0.3\n",
            "temperature: 64\n",
            "Epoch 1: Class_accuracy: 98.94%\n",
            "Epoch 2: Class_accuracy: 98.98%\n",
            "Epoch 3: Class_accuracy: 98.99%\n",
            "Epoch 4: Class_accuracy: 98.98%\n",
            "Epoch 5: Class_accuracy: 98.96%\n",
            "Epoch 6: Class_accuracy: 98.96%\n",
            "Epoch 7: Class_accuracy: 98.94%\n",
            "Epoch 8: Class_accuracy: 98.91%\n",
            "Epoch 9: Class_accuracy: 99.00%\n",
            "Epoch 10: Class_accuracy: 98.97%\n",
            "Epoch 11: Class_accuracy: 98.95%\n",
            "Epoch 12: Class_accuracy: 98.95%\n",
            "alpha: 0.5\n",
            "temperature: 1\n",
            "Epoch 1: Class_accuracy: 98.60%\n",
            "Epoch 2: Class_accuracy: 98.69%\n",
            "Epoch 3: Class_accuracy: 98.77%\n",
            "Epoch 4: Class_accuracy: 98.97%\n",
            "Epoch 5: Class_accuracy: 98.96%\n",
            "Epoch 6: Class_accuracy: 98.74%\n",
            "Epoch 7: Class_accuracy: 98.78%\n",
            "Epoch 8: Class_accuracy: 98.54%\n",
            "Epoch 9: Class_accuracy: 98.92%\n",
            "Epoch 10: Class_accuracy: 98.79%\n",
            "Epoch 11: Class_accuracy: 98.88%\n",
            "Epoch 12: Class_accuracy: 98.87%\n",
            "alpha: 0.5\n",
            "temperature: 2\n",
            "Epoch 1: Class_accuracy: 98.93%\n",
            "Epoch 2: Class_accuracy: 98.95%\n",
            "Epoch 3: Class_accuracy: 98.96%\n",
            "Epoch 4: Class_accuracy: 98.94%\n",
            "Epoch 5: Class_accuracy: 98.91%\n",
            "Epoch 6: Class_accuracy: 98.99%\n",
            "Epoch 7: Class_accuracy: 98.92%\n",
            "Epoch 8: Class_accuracy: 98.94%\n",
            "Epoch 9: Class_accuracy: 98.95%\n",
            "Epoch 10: Class_accuracy: 98.97%\n",
            "Epoch 11: Class_accuracy: 98.95%\n",
            "Epoch 12: Class_accuracy: 98.89%\n",
            "alpha: 0.5\n",
            "temperature: 4\n",
            "Epoch 1: Class_accuracy: 98.96%\n",
            "Epoch 2: Class_accuracy: 98.94%\n",
            "Epoch 3: Class_accuracy: 98.92%\n",
            "Epoch 4: Class_accuracy: 99.01%\n",
            "Epoch 5: Class_accuracy: 98.99%\n",
            "Epoch 6: Class_accuracy: 98.97%\n",
            "Epoch 7: Class_accuracy: 98.98%\n",
            "Epoch 8: Class_accuracy: 98.97%\n",
            "Epoch 9: Class_accuracy: 98.96%\n",
            "Epoch 10: Class_accuracy: 98.96%\n",
            "Epoch 11: Class_accuracy: 98.99%\n",
            "Epoch 12: Class_accuracy: 98.92%\n",
            "alpha: 0.5\n",
            "temperature: 16\n",
            "Epoch 1: Class_accuracy: 98.98%\n",
            "Epoch 2: Class_accuracy: 98.94%\n",
            "Epoch 3: Class_accuracy: 98.95%\n",
            "Epoch 4: Class_accuracy: 98.98%\n",
            "Epoch 5: Class_accuracy: 98.97%\n",
            "Epoch 6: Class_accuracy: 98.98%\n",
            "Epoch 7: Class_accuracy: 98.95%\n",
            "Epoch 8: Class_accuracy: 98.95%\n",
            "Epoch 9: Class_accuracy: 98.93%\n",
            "Epoch 10: Class_accuracy: 98.96%\n",
            "Epoch 11: Class_accuracy: 99.00%\n",
            "Epoch 12: Class_accuracy: 98.98%\n",
            "alpha: 0.5\n",
            "temperature: 32\n",
            "Epoch 1: Class_accuracy: 99.01%\n",
            "Epoch 2: Class_accuracy: 98.95%\n",
            "Epoch 3: Class_accuracy: 98.99%\n",
            "Epoch 4: Class_accuracy: 99.01%\n",
            "Epoch 5: Class_accuracy: 98.98%\n",
            "Epoch 6: Class_accuracy: 98.99%\n",
            "Epoch 7: Class_accuracy: 98.99%\n",
            "Epoch 8: Class_accuracy: 98.98%\n",
            "Epoch 9: Class_accuracy: 98.96%\n",
            "Epoch 10: Class_accuracy: 98.96%\n",
            "Epoch 11: Class_accuracy: 98.94%\n",
            "Epoch 12: Class_accuracy: 98.97%\n",
            "alpha: 0.5\n",
            "temperature: 64\n",
            "Epoch 1: Class_accuracy: 98.99%\n",
            "Epoch 2: Class_accuracy: 98.99%\n",
            "Epoch 3: Class_accuracy: 98.93%\n",
            "Epoch 4: Class_accuracy: 98.95%\n",
            "Epoch 5: Class_accuracy: 98.98%\n",
            "Epoch 6: Class_accuracy: 98.94%\n",
            "Epoch 7: Class_accuracy: 98.95%\n",
            "Epoch 8: Class_accuracy: 98.97%\n",
            "Epoch 9: Class_accuracy: 98.96%\n",
            "Epoch 10: Class_accuracy: 98.93%\n",
            "Epoch 11: Class_accuracy: 98.93%\n",
            "Epoch 12: Class_accuracy: 98.98%\n",
            "alpha: 0.7\n",
            "temperature: 1\n",
            "Epoch 1: Class_accuracy: 98.77%\n",
            "Epoch 2: Class_accuracy: 98.75%\n",
            "Epoch 3: Class_accuracy: 98.82%\n",
            "Epoch 4: Class_accuracy: 98.86%\n",
            "Epoch 5: Class_accuracy: 98.99%\n",
            "Epoch 6: Class_accuracy: 99.04%\n",
            "Epoch 7: Class_accuracy: 98.73%\n",
            "Epoch 8: Class_accuracy: 98.88%\n",
            "Epoch 9: Class_accuracy: 98.85%\n",
            "Epoch 10: Class_accuracy: 99.00%\n",
            "Epoch 11: Class_accuracy: 98.85%\n",
            "Epoch 12: Class_accuracy: 98.86%\n",
            "alpha: 0.7\n",
            "temperature: 2\n",
            "Epoch 1: Class_accuracy: 98.97%\n",
            "Epoch 2: Class_accuracy: 98.89%\n",
            "Epoch 3: Class_accuracy: 98.85%\n",
            "Epoch 4: Class_accuracy: 99.01%\n",
            "Epoch 5: Class_accuracy: 98.93%\n",
            "Epoch 6: Class_accuracy: 98.89%\n",
            "Epoch 7: Class_accuracy: 98.97%\n",
            "Epoch 8: Class_accuracy: 98.95%\n",
            "Epoch 9: Class_accuracy: 98.94%\n",
            "Epoch 10: Class_accuracy: 99.02%\n",
            "Epoch 11: Class_accuracy: 98.87%\n",
            "Epoch 12: Class_accuracy: 99.06%\n",
            "alpha: 0.7\n",
            "temperature: 4\n",
            "Epoch 1: Class_accuracy: 99.00%\n",
            "Epoch 2: Class_accuracy: 98.97%\n",
            "Epoch 3: Class_accuracy: 98.93%\n",
            "Epoch 4: Class_accuracy: 98.94%\n",
            "Epoch 5: Class_accuracy: 98.90%\n",
            "Epoch 6: Class_accuracy: 98.96%\n",
            "Epoch 7: Class_accuracy: 98.90%\n",
            "Epoch 8: Class_accuracy: 98.94%\n",
            "Epoch 9: Class_accuracy: 98.87%\n",
            "Epoch 10: Class_accuracy: 98.95%\n",
            "Epoch 11: Class_accuracy: 98.94%\n",
            "Epoch 12: Class_accuracy: 98.89%\n",
            "alpha: 0.7\n",
            "temperature: 16\n",
            "Epoch 1: Class_accuracy: 98.97%\n",
            "Epoch 2: Class_accuracy: 98.98%\n",
            "Epoch 3: Class_accuracy: 98.96%\n",
            "Epoch 4: Class_accuracy: 98.92%\n",
            "Epoch 5: Class_accuracy: 98.95%\n",
            "Epoch 6: Class_accuracy: 98.95%\n",
            "Epoch 7: Class_accuracy: 98.93%\n",
            "Epoch 8: Class_accuracy: 98.95%\n",
            "Epoch 9: Class_accuracy: 98.93%\n",
            "Epoch 10: Class_accuracy: 98.92%\n",
            "Epoch 11: Class_accuracy: 98.95%\n",
            "Epoch 12: Class_accuracy: 98.92%\n",
            "alpha: 0.7\n",
            "temperature: 32\n",
            "Epoch 1: Class_accuracy: 98.95%\n",
            "Epoch 2: Class_accuracy: 98.93%\n",
            "Epoch 3: Class_accuracy: 98.93%\n",
            "Epoch 4: Class_accuracy: 98.95%\n",
            "Epoch 5: Class_accuracy: 98.96%\n",
            "Epoch 6: Class_accuracy: 98.94%\n",
            "Epoch 7: Class_accuracy: 98.90%\n",
            "Epoch 8: Class_accuracy: 98.95%\n",
            "Epoch 9: Class_accuracy: 98.91%\n",
            "Epoch 10: Class_accuracy: 98.90%\n",
            "Epoch 11: Class_accuracy: 98.92%\n",
            "Epoch 12: Class_accuracy: 98.91%\n",
            "alpha: 0.7\n",
            "temperature: 64\n",
            "Epoch 1: Class_accuracy: 98.90%\n",
            "Epoch 2: Class_accuracy: 98.91%\n",
            "Epoch 3: Class_accuracy: 98.88%\n",
            "Epoch 4: Class_accuracy: 98.91%\n",
            "Epoch 5: Class_accuracy: 98.92%\n",
            "Epoch 6: Class_accuracy: 98.94%\n",
            "Epoch 7: Class_accuracy: 98.89%\n",
            "Epoch 8: Class_accuracy: 98.91%\n",
            "Epoch 9: Class_accuracy: 98.96%\n",
            "Epoch 10: Class_accuracy: 98.91%\n",
            "Epoch 11: Class_accuracy: 98.97%\n",
            "Epoch 12: Class_accuracy: 98.92%\n"
          ]
        }
      ],
      "source": [
        "# your code start from here for step 5 \n",
        "ALPHA_LIST = [0.3, 0.5, 0.7] # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE_LIST = [1, 2, 4, 16, 32, 64] #temperature hyperparameter\n",
        "\n",
        "train_and_evaluate(cnn_model, compute_teacher_loss)\n",
        "\n",
        "for a in ALPHA_LIST:\n",
        "  for t in DISTILLATION_TEMPERATURE_LIST:\n",
        "    print(\"alpha:\", a)\n",
        "    print(\"temperature:\", t)\n",
        "    ALPHA = a\n",
        "    DISTILLATION_TEMPERATURE = t\n",
        "    train_and_evaluate(fc_model, compute_student_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj1N38fnRTNB"
      },
      "source": [
        "# Test accuracy vs. tempreture curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gX4dbazrRWIz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f02caf5b-1cfe-4c1f-db54-dcc8c2b9fafb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Class_accuracy: 99.07%\n",
            "Epoch 2: Class_accuracy: 99.05%\n",
            "Epoch 3: Class_accuracy: 99.23%\n",
            "Epoch 4: Class_accuracy: 99.27%\n",
            "Epoch 5: Class_accuracy: 99.29%\n",
            "Epoch 6: Class_accuracy: 99.46%\n",
            "Epoch 7: Class_accuracy: 99.35%\n",
            "Epoch 8: Class_accuracy: 99.19%\n",
            "Epoch 9: Class_accuracy: 99.32%\n",
            "Epoch 10: Class_accuracy: 99.36%\n",
            "Epoch 11: Class_accuracy: 99.30%\n",
            "Epoch 12: Class_accuracy: 99.41%\n",
            "Epoch 1: Class_accuracy: 98.75%\n",
            "Epoch 2: Class_accuracy: 98.77%\n",
            "Epoch 3: Class_accuracy: 98.68%\n",
            "Epoch 4: Class_accuracy: 98.85%\n",
            "Epoch 5: Class_accuracy: 98.94%\n",
            "Epoch 6: Class_accuracy: 98.90%\n",
            "Epoch 7: Class_accuracy: 99.05%\n",
            "Epoch 8: Class_accuracy: 98.99%\n",
            "Epoch 9: Class_accuracy: 98.88%\n",
            "Epoch 10: Class_accuracy: 98.86%\n",
            "Epoch 11: Class_accuracy: 98.90%\n",
            "Epoch 12: Class_accuracy: 98.75%\n",
            "Epoch 1: Class_accuracy: 99.02%\n",
            "Epoch 2: Class_accuracy: 98.96%\n",
            "Epoch 3: Class_accuracy: 99.02%\n",
            "Epoch 4: Class_accuracy: 99.14%\n",
            "Epoch 5: Class_accuracy: 98.98%\n",
            "Epoch 6: Class_accuracy: 99.04%\n",
            "Epoch 7: Class_accuracy: 99.11%\n",
            "Epoch 8: Class_accuracy: 99.06%\n",
            "Epoch 9: Class_accuracy: 99.16%\n",
            "Epoch 10: Class_accuracy: 99.06%\n",
            "Epoch 11: Class_accuracy: 99.07%\n",
            "Epoch 12: Class_accuracy: 99.04%\n",
            "Epoch 1: Class_accuracy: 99.11%\n",
            "Epoch 2: Class_accuracy: 99.11%\n",
            "Epoch 3: Class_accuracy: 99.05%\n",
            "Epoch 4: Class_accuracy: 99.17%\n",
            "Epoch 5: Class_accuracy: 99.16%\n",
            "Epoch 6: Class_accuracy: 99.10%\n",
            "Epoch 7: Class_accuracy: 99.11%\n",
            "Epoch 8: Class_accuracy: 99.15%\n",
            "Epoch 9: Class_accuracy: 99.14%\n",
            "Epoch 10: Class_accuracy: 99.12%\n",
            "Epoch 11: Class_accuracy: 99.14%\n",
            "Epoch 12: Class_accuracy: 99.08%\n",
            "Epoch 1: Class_accuracy: 99.16%\n",
            "Epoch 2: Class_accuracy: 99.14%\n",
            "Epoch 3: Class_accuracy: 99.12%\n",
            "Epoch 4: Class_accuracy: 99.17%\n",
            "Epoch 5: Class_accuracy: 99.14%\n",
            "Epoch 6: Class_accuracy: 99.15%\n",
            "Epoch 7: Class_accuracy: 99.09%\n",
            "Epoch 8: Class_accuracy: 99.17%\n",
            "Epoch 9: Class_accuracy: 99.13%\n",
            "Epoch 10: Class_accuracy: 99.16%\n",
            "Epoch 11: Class_accuracy: 99.15%\n",
            "Epoch 12: Class_accuracy: 99.14%\n",
            "Epoch 1: Class_accuracy: 99.14%\n",
            "Epoch 2: Class_accuracy: 99.15%\n",
            "Epoch 3: Class_accuracy: 99.13%\n",
            "Epoch 4: Class_accuracy: 99.10%\n",
            "Epoch 5: Class_accuracy: 99.10%\n",
            "Epoch 6: Class_accuracy: 99.09%\n",
            "Epoch 7: Class_accuracy: 99.13%\n",
            "Epoch 8: Class_accuracy: 99.11%\n",
            "Epoch 9: Class_accuracy: 99.14%\n",
            "Epoch 10: Class_accuracy: 99.16%\n",
            "Epoch 11: Class_accuracy: 99.16%\n",
            "Epoch 12: Class_accuracy: 99.15%\n",
            "Epoch 1: Class_accuracy: 99.10%\n",
            "Epoch 2: Class_accuracy: 99.08%\n",
            "Epoch 3: Class_accuracy: 99.11%\n",
            "Epoch 4: Class_accuracy: 99.14%\n",
            "Epoch 5: Class_accuracy: 99.14%\n",
            "Epoch 6: Class_accuracy: 99.12%\n",
            "Epoch 7: Class_accuracy: 99.13%\n",
            "Epoch 8: Class_accuracy: 99.13%\n",
            "Epoch 9: Class_accuracy: 99.15%\n",
            "Epoch 10: Class_accuracy: 99.10%\n",
            "Epoch 11: Class_accuracy: 99.13%\n",
            "Epoch 12: Class_accuracy: 99.14%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# your code start from here for step 6\n",
        "DISTILLATION_TEMPERATURE_LIST = [1, 2, 4, 16, 32, 64]\n",
        "max_acc = []\n",
        "ALPHA = 0.5\n",
        "train_and_evaluate(cnn_model, compute_teacher_loss)\n",
        "\n",
        "for t in DISTILLATION_TEMPERATURE_LIST:\n",
        "    DISTILLATION_TEMPERATURE = t\n",
        "    fc_model.reset_metrics()\n",
        "    max_acc.append(train_and_evaluate(fc_model, compute_student_loss))\n",
        "\n",
        "plt.title(\"Test accuracy vs. tempreture curve\")\n",
        "plt.plot(DISTILLATION_TEMPERATURE_LIST,max_acc, label='\"max test accuracy')\n",
        "plt.xlabel('Tempreture')\n",
        "plt.ylabel('Accuracy %')\n",
        "plt.legend()\n",
        "plt.savefig(\"Test_accuracy_vs_t.png\")\n",
        "plt.show()\n",
        "plt.clf()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNrH_1emRbGA"
      },
      "source": [
        "# Train student from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjospsxIRbQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3eb6245-d955-4913-8744-edd8d883f3eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Class_accuracy: 96.74%\n",
            "Epoch 2: Class_accuracy: 97.71%\n",
            "Epoch 3: Class_accuracy: 97.63%\n",
            "Epoch 4: Class_accuracy: 98.10%\n",
            "Epoch 5: Class_accuracy: 98.04%\n",
            "Epoch 6: Class_accuracy: 97.78%\n",
            "Epoch 7: Class_accuracy: 98.37%\n",
            "Epoch 8: Class_accuracy: 98.11%\n",
            "Epoch 9: Class_accuracy: 97.91%\n",
            "Epoch 10: Class_accuracy: 98.19%\n",
            "Epoch 11: Class_accuracy: 98.30%\n",
            "Epoch 12: Class_accuracy: 98.16%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=98.369995>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Build fully connected student.\n",
        "fc_model_no_distillation = tf.keras.Sequential()\n",
        "\n",
        "# your code start from here for step 7\n",
        "fc_model_no_distillation.add(tf.keras.layers.Flatten(input_shape=( 28, 28,1)))\n",
        "fc_model_no_distillation.add(tf.keras.layers.Dense(748, activation=\"relu\"))\n",
        "fc_model_no_distillation.add(tf.keras.layers.Dense(748, activation=\"relu\"))\n",
        "fc_model_no_distillation.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
        "\n",
        "\n",
        "#@ test {\"output\": \"ignore\"}\n",
        "\n",
        "def compute_plain_cross_entropy_loss(images, labels):\n",
        "  \"\"\"Compute plain loss for given images and labels.\n",
        "\n",
        "  For fair comparison and convenience, this function also performs a\n",
        "  LogSumExp over subclasses, but does not perform subclass distillation.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  # your code start from here for step 7\n",
        "\n",
        "  student_subclass_logits = fc_model_no_distillation(images, training=True)\n",
        "  cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=student_subclass_logits))\n",
        "  \n",
        "  return cross_entropy_loss\n",
        "\n",
        "\n",
        "train_and_evaluate(fc_model_no_distillation, compute_plain_cross_entropy_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq3JTpQ4RuhR"
      },
      "source": [
        "# Comparing the teacher and student model (number of of parameters and FLOPs) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4V8GB2yRRuxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae792f6-71c5-4c5a-c928-e8b111aeadd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher FLOPS: 0.022 G\n",
            "student FLOPS: 0.00231 G\n",
            "teacher parameters: 1011466.0\n",
            "student parameters: 1154922.0\n"
          ]
        }
      ],
      "source": [
        "# your code start from here for step 8\n",
        "\n",
        "student_flops = get_flops(fc_model, batch_size=1)\n",
        "teacher_flops = get_flops(cnn_model, batch_size=1)\n",
        "print(f\"teacher FLOPS: {teacher_flops / 10 ** 9:.03} G\")\n",
        "print(f\"student FLOPS: {student_flops / 10 ** 9:.03} G\")\n",
        "def parameter_count(model):\n",
        "  trainableParams = numpy.sum([numpy.prod(v.get_shape()) for v in model.trainable_weights])\n",
        "  nonTrainableParams = numpy.sum([numpy.prod(v.get_shape()) for v in model.non_trainable_weights])\n",
        "  totalParams = trainableParams + nonTrainableParams\n",
        "  return totalParams\n",
        "\n",
        "print(\"teacher parameters:\", parameter_count(cnn_model))\n",
        "print(\"student parameters:\", parameter_count(fc_model))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjwJ5oziRvRn"
      },
      "source": [
        "# Implementing the state-of-the-art KD algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q10lybAFRvZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ce1245-3a39-4831-b19b-00492946acc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Class_accuracy: 97.79%\n",
            "Epoch 2: Class_accuracy: 98.51%\n",
            "Epoch 3: Class_accuracy: 98.94%\n",
            "Epoch 4: Class_accuracy: 98.83%\n",
            "Epoch 5: Class_accuracy: 98.90%\n",
            "Epoch 6: Class_accuracy: 98.96%\n",
            "Epoch 7: Class_accuracy: 99.10%\n",
            "Epoch 8: Class_accuracy: 99.22%\n",
            "Epoch 9: Class_accuracy: 99.21%\n",
            "Epoch 10: Class_accuracy: 99.21%\n",
            "Epoch 11: Class_accuracy: 99.25%\n",
            "Epoch 12: Class_accuracy: 99.24%\n",
            "Epoch 1: Class_accuracy: 97.51%\n",
            "Epoch 2: Class_accuracy: 98.26%\n",
            "Epoch 3: Class_accuracy: 98.39%\n",
            "Epoch 4: Class_accuracy: 98.54%\n",
            "Epoch 5: Class_accuracy: 98.65%\n",
            "Epoch 6: Class_accuracy: 98.76%\n",
            "Epoch 7: Class_accuracy: 98.69%\n",
            "Epoch 8: Class_accuracy: 98.68%\n",
            "Epoch 9: Class_accuracy: 98.76%\n",
            "Epoch 10: Class_accuracy: 98.79%\n",
            "Epoch 11: Class_accuracy: 98.86%\n",
            "Epoch 12: Class_accuracy: 98.84%\n",
            "Epoch 1: Class_accuracy: 96.52%\n",
            "Epoch 2: Class_accuracy: 97.83%\n",
            "Epoch 3: Class_accuracy: 98.11%\n",
            "Epoch 4: Class_accuracy: 98.34%\n",
            "Epoch 5: Class_accuracy: 98.37%\n",
            "Epoch 6: Class_accuracy: 98.53%\n",
            "Epoch 7: Class_accuracy: 98.49%\n",
            "Epoch 8: Class_accuracy: 98.38%\n",
            "Epoch 9: Class_accuracy: 98.53%\n",
            "Epoch 10: Class_accuracy: 98.67%\n",
            "Epoch 11: Class_accuracy: 98.68%\n",
            "Epoch 12: Class_accuracy: 98.59%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=98.68>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# your code start from here for step 12\n",
        "\n",
        "# Build CNN TA.\n",
        "ta_cnn_model = tf.keras.Sequential()\n",
        "\n",
        "ta_cnn_model.add(tf.keras.layers.Conv2D(32, (3,3), strides=1, activation=\"relu\",input_shape=(28, 28,1)))\n",
        "ta_cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=1))\n",
        "ta_cnn_model.add(tf.keras.layers.Flatten())\n",
        "ta_cnn_model.add(tf.keras.layers.Dropout(0.5))\n",
        "ta_cnn_model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
        "ta_cnn_model.add(tf.keras.layers.Dropout(0.5))\n",
        "ta_cnn_model.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
        "\n",
        "\n",
        "# Build CNN teacher.\n",
        "cnn_model = tf.keras.Sequential()\n",
        "\n",
        "cnn_model.add(tf.keras.layers.Conv2D(32, (3,3), strides=1, activation=\"relu\",input_shape=(28, 28,1)))\n",
        "cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=1))\n",
        "cnn_model.add(tf.keras.layers.Conv2D(64, (3,3), strides=1, activation=\"relu\"))\n",
        "cnn_model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=2))\n",
        "cnn_model.add(tf.keras.layers.Flatten())\n",
        "cnn_model.add(tf.keras.layers.Dropout(0.5))\n",
        "cnn_model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
        "cnn_model.add(tf.keras.layers.Dropout(0.5))\n",
        "cnn_model.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
        "\n",
        "\n",
        "# Build fully connected student.\n",
        "\n",
        "fc_model = tf.keras.Sequential()\n",
        "fc_model.add(tf.keras.layers.Flatten(input_shape=( 28, 28,1)))\n",
        "fc_model.add(tf.keras.layers.Dense(748, activation=\"relu\"))\n",
        "fc_model.add(tf.keras.layers.Dense(748, activation=\"relu\"))\n",
        "fc_model.add(tf.keras.layers.Dense(NUM_CLASSES))\n",
        "\n",
        "ALPHA = 0.7 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 4. #temperature hyperparameter\n",
        "\n",
        "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
        "                      temperature: Union[float, tf.Tensor]):\n",
        "  \"\"\"Compute distillation loss.\n",
        "\n",
        "  This function computes cross entropy between softened logits and softened\n",
        "  targets. The resulting loss is scaled by the squared temperature so that\n",
        "  the gradient magnitude remains approximately constant as the temperature is\n",
        "  changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
        "  a neural network.\"\n",
        "\n",
        "  Args:\n",
        "    teacher_logits: A Tensor of logits provided by the teacher.\n",
        "    student_logits: A Tensor of logits provided by the student, of the same\n",
        "      shape as `teacher_logits`.\n",
        "    temperature: Temperature to use for distillation.\n",
        "\n",
        "  Returns:\n",
        "    A scalar Tensor containing the distillation loss.\n",
        "  \"\"\"\n",
        "  soft_targets = tf.exp(teacher_logits/temperature) / tf.reduce_sum(tf.exp(teacher_logits/temperature), -1, keepdims=True)\n",
        "\n",
        "  return tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "@tf.function\n",
        "def compute_teacher_loss(images, labels):\n",
        "  \"\"\"Compute subclass knowledge distillation teacher loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  subclass_logits = cnn_model(images, training=True)\n",
        "\n",
        "  # Compute cross-entropy loss for subclasses.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "  cross_entropy_loss_value=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=subclass_logits))\n",
        "  #cee = tf.keras.losses.CategoricalCrossentropy()\n",
        "  #cross_entropy_loss_value = cee(labels, subclass_logits).numpy()\n",
        "\n",
        "\n",
        "  return cross_entropy_loss_value\n",
        "  \n",
        "def compute_ta_loss_from_teacher(images, labels):\n",
        "  \"\"\"Compute subclass knowledge distillation student loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  ta_subclass_logits = ta_cnn_model(images, training=True)\n",
        "\n",
        "  # Compute subclass distillation loss between student subclass logits and\n",
        "  # softened teacher subclass targets probabilities.\n",
        "\n",
        "\n",
        "  teacher_subclass_logits = cnn_model(images, training=False)\n",
        "  distillation_loss_value =distillation_loss(teacher_subclass_logits,ta_subclass_logits,DISTILLATION_TEMPERATURE)\n",
        "\n",
        "  # Compute cross-entropy loss with hard targets.\n",
        "\n",
        "\n",
        "\n",
        "  cross_entropy_loss_value = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=ta_subclass_logits))\n",
        "\n",
        "  return ALPHA*distillation_loss_value+(1-ALPHA)*cross_entropy_loss_value\n",
        "\n",
        "def compute_student_loss_from_ta(images, labels):\n",
        "  \"\"\"Compute subclass knowledge distillation student loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  student_subclass_logits = fc_model(images, training=True)\n",
        "\n",
        "  # Compute subclass distillation loss between student subclass logits and\n",
        "  # softened teacher subclass targets probabilities.\n",
        "\n",
        "\n",
        "  ta_subclass_logits = ta_cnn_model(images, training=False)\n",
        "  distillation_loss_value =distillation_loss(ta_subclass_logits,student_subclass_logits,DISTILLATION_TEMPERATURE)\n",
        "\n",
        "  # Compute cross-entropy loss with hard targets.\n",
        "\n",
        "  cross_entropy_loss_value = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=student_subclass_logits))\n",
        "\n",
        "  return ALPHA*distillation_loss_value+(1-ALPHA)*cross_entropy_loss_value\n",
        "\n",
        "\n",
        "train_and_evaluate(cnn_model, compute_teacher_loss)\n",
        "train_and_evaluate(ta_cnn_model, compute_ta_loss_from_teacher)\n",
        "train_and_evaluate(fc_model, compute_student_loss_from_ta)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dsOmtqdieIC"
      },
      "source": [
        "# (Optional) XAI method to explain models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0IMIFW8ilPO"
      },
      "outputs": [],
      "source": [
        "# your code start from here for step 13\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8243bedb0c904be0b0fe0dc96604e0a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45c7cc4619bf47abb1cd976141d091bc",
              "IPY_MODEL_e62dc2c9605a42988b2e47b0e35b2f30",
              "IPY_MODEL_e0f1d2dd3cf646899ff82ff53b58ebf1"
            ],
            "layout": "IPY_MODEL_dd9d6bba363d4fe590d7237576f70ea9"
          }
        },
        "45c7cc4619bf47abb1cd976141d091bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18fd9d363c81431daaa918f9963f80f6",
            "placeholder": "",
            "style": "IPY_MODEL_957c4be3e82a4fcabcab21abe0c9d780",
            "value": "Dl Completed...: 100%"
          }
        },
        "e62dc2c9605a42988b2e47b0e35b2f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35e6aaa9cf1246488a43dfb216d2ef90",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9ea82867511487b8e494927542ec44b",
            "value": 4
          }
        },
        "e0f1d2dd3cf646899ff82ff53b58ebf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1902bcc505849918ca9dce2af531d3b",
            "placeholder": "",
            "style": "IPY_MODEL_87e41978fe394e3f839dda884a66301b",
            "value": " 4/4 [00:04&lt;00:00,  1.25s/ file]"
          }
        },
        "dd9d6bba363d4fe590d7237576f70ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18fd9d363c81431daaa918f9963f80f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "957c4be3e82a4fcabcab21abe0c9d780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35e6aaa9cf1246488a43dfb216d2ef90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ea82867511487b8e494927542ec44b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1902bcc505849918ca9dce2af531d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87e41978fe394e3f839dda884a66301b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}